{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert - POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBaseMultilingualEmbeddingApi:\n",
    "    \n",
    "    def __init__(self, model_name=\"bert-base-multilingual-cased\", cuda=True):\n",
    "        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.tokens_tensor = None\n",
    "        self.segments_tensor = None\n",
    "        \n",
    "        self.encoded_layers_ = None\n",
    "        self.token_embeddings_ = None\n",
    "        \n",
    "    def _tokenize_text(self, text):\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = self.tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        \n",
    "        self.tokens_tensor = torch.tensor([indexed_tokens]).to(self.device)\n",
    "        self.segments_tensor = torch.tensor([segments_ids]).to(self.device)\n",
    "    \n",
    "    def _evaluate(self):\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = self.model(self.tokens_tensor, self.segments_tensor)\n",
    "        self.encoded_layers_ = encoded_layers\n",
    "    \n",
    "    def _generate_token_embeddings(self, batch_i=0):\n",
    "        \"\"\"\n",
    "        Convert the hidden state embeddings into single token vectors\n",
    "        Holds the list of 12 layer embeddings for each token\n",
    "        Will have the shape: [# tokens, # layers, # features]\n",
    "        \"\"\"\n",
    "        token_embeddings = [] \n",
    "        # For each token in the sentence...\n",
    "        for token_i in range(len(self.encoded_layers_[-1][batch_i])):\n",
    "            # Holds 12 layers of hidden states for each token \n",
    "            hidden_layers = [] \n",
    "            # For each of the 12 layers...\n",
    "            for layer_i in range(len(self.encoded_layers_)):\n",
    "            # Lookup the vector for `token_i` in `layer_i`\n",
    "                vec = self.encoded_layers_[layer_i][batch_i][token_i]\n",
    "                hidden_layers.append(vec)\n",
    "            token_embeddings.append(hidden_layers)\n",
    "        self.token_embeddings_ = token_embeddings\n",
    "    \n",
    "    def feed_forward(self, sentence):\n",
    "        self._tokenize_text(sentence)\n",
    "        self._evaluate()\n",
    "        self._generate_token_embeddings()\n",
    "    \n",
    "    def create_word_embedding_(self, how=\"cat_last_4\"):\n",
    "        if how == \"cat_last_4\":\n",
    "            return [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in self.token_embeddings_]\n",
    "        elif how == \"sum_last_4\":\n",
    "            return [torch.sum(torch.stack(layer)[-4:], 0) for layer in self.token_embeddings_]\n",
    "        else:\n",
    "            print(\"Redefine `how` parameter\")\n",
    "        \n",
    "    def create_sentence_embedding_(self, how=\"mean_last_layer\"):\n",
    "        if how == \"mean_last_layer\":\n",
    "            return torch.mean(self.encoded_layers_[-1], 1).squeeze()\n",
    "        else:\n",
    "            print(\"Redefine `how` parameter\")\n",
    "            \n",
    "    def print_dimensions_(self):\n",
    "        print (\"Number of layers:\", len(self.encoded_layers_))\n",
    "        layer_i = 0\n",
    "        print (\"Number of batches:\", len(self.encoded_layers_[layer_i]))\n",
    "        batch_i = 0\n",
    "        print (\"Number of tokens:\", len(self.encoded_layers_[layer_i][batch_i]))\n",
    "        token_i = 0\n",
    "        print (\"Number of hidden units:\", len(self.encoded_layers_[layer_i][batch_i][token_i]))\n",
    "        \n",
    "    def plot_embedding_hist(self, vec):\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.distplot(vec)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from pprint import pprint\n",
    "NUMBER_OF_FILES_TO_OPEN = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tomasza <Entity name=\"Tomasz Sekielski\" type=\"person\" '\n",
      " 'category=\"dziennikarze\">Sekielskiego</Entity> oburzyła wypowiedź prof. '\n",
      " 'Mariana Filara. Wybitny prawnik stwierdził, że nawet jeśli znalezione w celi '\n",
      " 'Mariusza T. to prowokacja - postąpiono słusznie. - Nie wiem, co się stało '\n",
      " 'profesorowi. Proponuje bardzo niebezpieczną drogę. Mariusz T. nigdy nie '\n",
      " 'powinien wyjść na wolność. Ale nie można w tym celu łamać prawa - mówił '\n",
      " '<Entity name=\"Tomasz Sekielski\" type=\"person\" '\n",
      " 'category=\"dziennikarze\">Sekielski</Entity> w TOK FM. \"Człowiek, który '\n",
      " 'zdecydował o podrzuceniu Mariuszowi T. do celi kompromitujących materiałów, '\n",
      " 'postawił na szali jedne wartości przeciw drugim. Postawił naruszenie prawa '\n",
      " 'przeciw ludzkiemu bezpieczeństwu. W mojej ocenie wybrał słusznie\" - tak w '\n",
      " 'wywiadzie dla \"Gazety Wyborczej\" prof. <Entity name=\"Marian Filar\" '\n",
      " 'type=\"person\" category=\"muzycy\">Marian Filar</Entity> komentował informacje '\n",
      " 'o znalezieniu w celi Mariusza T. materiałów z pornografią dziecięcą. Słowa '\n",
      " 'prawnika zaskoczyły i oburzyły <Entity name=\"Tomasz Sekielski\" type=\"person\" '\n",
      " 'category=\"dziennikarze\">Tomasza Sekielskiego</Entity>. Dziennikarz TVP '\n",
      " 'przyznał, że kiedy rozmowa ukazała się w internecie, przeczytał ją kilka '\n",
      " 'razy. Bo nie mógł uwierzyć, w to co zobaczył. - Nie wiem, co się stało panu '\n",
      " 'profesorowi. Prawnik tak często piętnujący naginanie prawa, wykorzystywanie '\n",
      " 'go do doraźnych celów politycznych, teraz ogłasza oto, że prawo jest '\n",
      " 'nieważne. Że w imię wyimaginowanej wyższej konieczności można nie tylko '\n",
      " 'manipulować prawem, ale także działać poza nim - komentował gospodarz '\n",
      " '\"Poranka Radia TOK FM\". Zdaniem <Entity name=\"Tomasz Sekielski\" '\n",
      " 'type=\"person\" category=\"dziennikarze\">Sekielskiego</Entity> prawnik z UMK w '\n",
      " 'Toruniu proponuje \"bardzo niebezpieczną drogę\". - Prowadzącą wprost do '\n",
      " 'państwa totalitarnego, w którym jakiś urzędnik lub polityk mogą dowolnie i '\n",
      " 'bezkarnie decydować o czyimś życiu. Tak na marginesie, może od razu '\n",
      " 'należałoby powołać szwadrony śmierci, by ostatecznie rozwiązywałyby '\n",
      " 'problemy. Dziennikarz nie ma wątpliwości - Mariusz T. nie powinien nigdy '\n",
      " 'wyjść z więzienia. - Ale nie można w tym celu łamać prawa, bo za chwilę w '\n",
      " 'podobnej sytuacji może się znaleźć nie tylko morderca-pedofil - powiedział '\n",
      " '<Entity name=\"Tomasz Sekielski\" type=\"person\" category=\"dziennikarze\">Tomasz '\n",
      " 'Sekielski</Entity>.')\n"
     ]
    }
   ],
   "source": [
    "corpusNews = list()\n",
    "for i in range(0,NUMBER_OF_FILES_TO_OPEN):\n",
    "    f = codecs.open(\"doc\"+str(i+1), \"r\", encoding = 'utf-8')\n",
    "    for line in f:\n",
    "        corpusNews.append(line)\n",
    "    f.close()\n",
    "pprint(corpusNews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are functions from Piter, that I did not changed (but use it differently):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_annotations(document : str):\n",
    "    '''\n",
    "    Searches for all occurances of '<' and '>' in the document.\n",
    "    Returns lists of indexes of occurances opening for '<' and closing for '>'\n",
    "    '''\n",
    "    i = 0\n",
    "    opening = list()\n",
    "    closing = list()\n",
    "    while i != -1:\n",
    "        i = document.find('<', i)\n",
    "        opening.append(i)\n",
    "        if i == -1:\n",
    "            closing.append(-1)\n",
    "            break\n",
    "        i = document.find('>', i)\n",
    "        closing.append(i)\n",
    "    closing = [cl + 1 for cl in closing]\n",
    "    closing[-1] = -1\n",
    "    return(opening, closing)\n",
    "\n",
    "def get_annotation_values(text : str): # jest typ nie type, bo type jest zarezerwowana nazwa, nie jestem uposledzony\n",
    "    '''\n",
    "    Returns a dict consisting annotation values {'name', 'typ', 'category'} for first occuring annotation\n",
    "    in the text.\n",
    "    '''\n",
    "    name_start = text.find('name=') + len('name=\\\"')\n",
    "    name_end = text.find('\\\"', name_start)\n",
    "    typ_start = text.find('type=', name_end) + len('type=\\\"')\n",
    "    typ_end = text.find('\\\"', typ_start)\n",
    "    category_start = text.find('category', typ_end) + len('category=\\\"')\n",
    "    category_end = text.find('\\\"', category_start)\n",
    "    return({'name' : text[name_start:name_end], 'typ' : text[typ_start:typ_end],\n",
    "               'category' : text[category_start:category_end]})\n",
    "\n",
    "def exclude_vectors_for_person(list_of_vectors, person):\n",
    "    '''\n",
    "    list_of_vectors - return value from exclude_sentence_vectors()\n",
    "    person - name of person from people_dict\n",
    "    '''\n",
    "    l = list()\n",
    "    for el in list_of_vectors:\n",
    "        if el[1] == person:\n",
    "            l.append(el[0])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our function for sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_sentence_vectors(text):\n",
    "    people_dict = {}\n",
    "    sentences = text.split(\".\")\n",
    "    contexts = []\n",
    "    for sentence in sentences:\n",
    "        opn, cls = find_annotations(sentence)\n",
    "        if opn[0] != -1:\n",
    "            annotation = get_annotation_values(sentence)\n",
    "            sentence = sentence[0:opn[0]] + sentence[cls[-2]:]\n",
    "            contexts.append([sentence, annotation[\"name\"]])\n",
    "            try:\n",
    "                people_dict[annotation[\"category\"]].add(annotation[\"name\"])\n",
    "            except KeyError:\n",
    "                people_dict[annotation[\"category\"]] = {annotation[\"name\"]}\n",
    "    return contexts, people_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tomasza  oburzyła wypowiedź prof', 'Tomasz Sekielski'], [' Ale nie można w tym celu łamać prawa - mówił  w TOK FM', 'Tomasz Sekielski'], ['  komentował informacje o znalezieniu w celi Mariusza T', 'Marian Filar'], [' Słowa prawnika zaskoczyły i oburzyły ', 'Tomasz Sekielski'], [' Zdaniem  prawnik z UMK w Toruniu proponuje \"bardzo niebezpieczną drogę\"', 'Tomasz Sekielski'], [' - Ale nie można w tym celu łamać prawa, bo za chwilę w podobnej sytuacji może się znaleźć nie tylko morderca-pedofil - powiedział ', 'Tomasz Sekielski']]\n",
      "{'dziennikarze': {'Tomasz Sekielski'}, 'muzycy': {'Marian Filar'}}\n"
     ]
    }
   ],
   "source": [
    "vectors, people_dict = exclude_sentence_vectors(corpusNews[0])\n",
    "print(vectors)\n",
    "print(people_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tomasza  oburzyła wypowiedź prof', ' Ale nie można w tym celu łamać prawa - mówił  w TOK FM', ' Słowa prawnika zaskoczyły i oburzyły ', ' Zdaniem  prawnik z UMK w Toruniu proponuje \"bardzo niebezpieczną drogę\"', ' - Ale nie można w tym celu łamać prawa, bo za chwilę w podobnej sytuacji może się znaleźć nie tylko morderca-pedofil - powiedział ']\n"
     ]
    }
   ],
   "source": [
    "print(exclude_vectors_for_person(vectors, \"Tomasz Sekielski\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create API object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
      "100%|██████████| 662804195/662804195 [10:41<00:00, 1032855.28B/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BertBaseMultilingualEmbeddingApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create sentence and pass to feed_forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Oszczędnością i pracą ludzie się bogacą.\"\n",
    "bert.feed_forward(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate word/sentence embedding, specify `how`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embeddings = bert.create_word_embedding_(how = \"sum_last_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_embedding = bert.create_sentence_embedding_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualize tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert.plot_embedding_hist(sent_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embeddings in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = 'minimalsample'\n",
    "NAME_TO_VISUALISE_VARIABLE = \"example_embeddings\"\n",
    "path_for_mnist_metadata =  'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_np = torch.stack(concatenated_lats_4_layers).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_var = tf.Variable(token_embeddings_np, name=NAME_TO_VISUALISE_VARIABLE)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Specify where you find the metadata\n",
    "embedding.metadata_path = path_for_mnist_metadata #'metadata.tsv'\n",
    "\n",
    "# Say that you want to visualise the embeddings\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_for_mnist_metadata,'w') as f:\n",
    "    f.write(\"Index\\tLabel\\n\")\n",
    "    for index,label in enumerate(tokenized_text):\n",
    "        f.write(\"%d\\t %s\\n\" % (index,label.encode('utf-8')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
